{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=center><font size = 5> <center>文本分析与挖掘</center> </font></h1> \n",
    "\n",
    "<h2 align=center><font size = 4><center>实验七、基于循环神经网络的情感分类</center></font></h2>\n",
    "<h2 align=center><font size = 2><center>浙江工业大学计算机科学与技术学院</center></font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、实验目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li>掌握基于进行分类的模型搭建和训练</li>\n",
    "<li>掌握不同 RNN 类型的调用</li>\n",
    "<li> 熟悉英文情感分类过程</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验内容\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li>基于循环神经网络对英文影评 IMDB 数据集进行分类。</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载IMDB数据集，并划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers, losses, optimizers, Sequential\n",
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的形状: (25000,)\n",
      "测试集的形状: (25000,)\n"
     ]
    }
   ],
   "source": [
    "max_review_len = 80 # 句子最大长度s，大于的句子部分将截断，小于的将填充\n",
    "max_word_num=60#词汇表数量\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_word_num)\n",
    "#打印输入的形状，标签的形状\n",
    "print(\"训练集的形状:\", x_train.shape)\n",
    "print(\"测试集的形状:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.tolist()\n",
    "x_test=x_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i]=tf.one_hot(x_train[i],max_word_num)\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i]=tf.one_hot(x_test[i],max_word_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.单层GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) 模型 1：单层 GRU（节点个数 128，激活 tanh），全连接（1个节点,激活 sigmoid）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=keras.models.Sequential(\n",
    "[\n",
    "\n",
    "keras.layers.GRU(128,input_shape=(max_review_len,max_word_num),activation=\"tanh\"),\n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])7\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) 设置 batchsize=32, 训练模型 1，得到测试集上的准确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 32 # 批量大小\n",
    "# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6723 - accuracy: 0.5839\n",
      "Epoch 2/10\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.6481 - accuracy: 0.6254\n",
      "Epoch 3/10\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.6394 - accuracy: 0.6331\n",
      "Epoch 4/10\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.6304 - accuracy: 0.6413\n",
      "Epoch 5/10\n",
      "781/781 [==============================] - 4s 4ms/step - loss: 0.6215 - accuracy: 0.6497\n",
      "Epoch 6/10\n",
      "781/781 [==============================] - 4s 4ms/step - loss: 0.6142 - accuracy: 0.6578\n",
      "Epoch 7/10\n",
      "781/781 [==============================] - 3s 4ms/step - loss: 0.6064 - accuracy: 0.6663\n",
      "Epoch 8/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.5997 - accuracy: 0.6734\n",
      "Epoch 9/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.5913 - accuracy: 0.6808\n",
      "Epoch 10/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.5834 - accuracy: 0.6890\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(15,8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 2s 2ms/step - loss: 0.6158 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6158457398414612, 0.6666933298110962]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.单层LSTM\n",
    "模型 2：把模型 1 中的 GRU 改成 LSTM，重复 1（b）实验，对比\n",
    "结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6660 - accuracy: 0.5968\n",
      "Epoch 2/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6460 - accuracy: 0.6283\n",
      "Epoch 3/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6411 - accuracy: 0.6337\n",
      "Epoch 4/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6386 - accuracy: 0.6370\n",
      "Epoch 5/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6344 - accuracy: 0.6408\n",
      "Epoch 6/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6285 - accuracy: 0.6450\n",
      "Epoch 7/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6238 - accuracy: 0.6475\n",
      "Epoch 8/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6156 - accuracy: 0.6579\n",
      "Epoch 9/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6105 - accuracy: 0.6617\n",
      "Epoch 10/10\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.6017 - accuracy: 0.6696\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential(\n",
    "[\n",
    "\n",
    "keras.layers.LSTM(128,input_shape=(max_review_len,max_word_num),activation=\"tanh\"),\n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "history=model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 2s 3ms/step - loss: 0.6308 - accuracy: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6308274269104004, 0.6509683132171631]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "准确率虽比单层GRU低，但总体性能类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 双层 GRU\n",
    "模型 3：双层 GRU(每层节点个数 128，激活 tanh)，全连接（1\n",
    "个节点,激活 sigmoid）。重复 1（b）实验，对比结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential(\n",
    "[\n",
    "\n",
    "keras.layers.GRU(128,input_shape=(max_review_len,max_word_num),activation=\"tanh\",return_sequences=True),\n",
    "keras.layers.GRU(128,activation=\"tanh\"),    \n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "781/781 [==============================] - 7s 8ms/step - loss: 0.6729 - accuracy: 0.5880\n",
      "Epoch 2/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.6488 - accuracy: 0.6236\n",
      "Epoch 3/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.6394 - accuracy: 0.6360\n",
      "Epoch 4/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.6288 - accuracy: 0.6443\n",
      "Epoch 5/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.6187 - accuracy: 0.6544\n",
      "Epoch 6/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.6112 - accuracy: 0.6624\n",
      "Epoch 7/10\n",
      "781/781 [==============================] - 6s 8ms/step - loss: 0.6017 - accuracy: 0.6690\n",
      "Epoch 8/10\n",
      "781/781 [==============================] - 7s 8ms/step - loss: 0.5950 - accuracy: 0.6773\n",
      "Epoch 9/10\n",
      "781/781 [==============================] - 7s 8ms/step - loss: 0.5836 - accuracy: 0.6859\n",
      "Epoch 10/10\n",
      "781/781 [==============================] - 7s 8ms/step - loss: 0.5716 - accuracy: 0.6969\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "history=model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 3s 4ms/step - loss: 0.6113 - accuracy: 0.6660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6113374829292297, 0.6659731268882751]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "使用双层GRU与单层GRU相比，在训练集上准确率上提升了0.01，在测试集上反而略微下降，两个模型的性能基本差不多，且预测的精度都不是很高。\n",
    "    \n",
    "我推测，由于内存的限制，只能将词汇表限制在60，丢失了大量的特征，所以单层与双层GRU效果类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.分别设置 batchsize=16 和 64，重复 1（b）实验，对比结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （a）batchsize=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 16 # 批量大小\n",
    "# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential(\n",
    "[\n",
    "\n",
    "keras.layers.GRU(128,input_shape=(max_review_len,max_word_num),activation=\"tanh\"),\n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.6698 - accuracy: 0.5926\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.6451 - accuracy: 0.6313\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.6338 - accuracy: 0.6384\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.6233 - accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.6133 - accuracy: 0.6589\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.6030 - accuracy: 0.6684\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.5921 - accuracy: 0.6807\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.5806 - accuracy: 0.6876\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.5663 - accuracy: 0.6991\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.5517 - accuracy: 0.7134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3b07eb550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 3s 2ms/step - loss: 0.6346 - accuracy: 0.6709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6346493363380432, 0.6709346771240234]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "    \n",
    "缩小batchsize后，可以发现每个轮次的训练次数增加了，模型的性能有略微的提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （b）batchsize=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 64 # 批量大小\n",
    "# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6755 - accuracy: 0.5765\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6488 - accuracy: 0.6257\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6428 - accuracy: 0.6303\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6375 - accuracy: 0.6385\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6299 - accuracy: 0.6404\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6258 - accuracy: 0.6481\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6191 - accuracy: 0.6538\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6131 - accuracy: 0.6593\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6062 - accuracy: 0.6672\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 0.6016 - accuracy: 0.6704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c34d4c0eb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.Sequential(\n",
    "[\n",
    "\n",
    "keras.layers.GRU(128,input_shape=(max_review_len,max_word_num),activation=\"tanh\"),\n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 1s 4ms/step - loss: 0.6134 - accuracy: 0.6619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.613368570804596, 0.6618990302085876]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "增大bitchsize后，每一轮训练次数变少了，训练的时间也降低了，但准确率提升不是很高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 模型 4：embedding 层（128 个节点），单层 GRU（节点个数 128，激活 tanh），全连接（1 个节点,激活 sigmoid）。重复 1（b）实验，对比结果，讨论降维的作用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_len = 120 # 句子最大长度s，大于的句子部分将截断，小于的将填充\n",
    "max_word_num=10000#词汇表数量\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_word_num)\n",
    "# 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "batchsz = 128 # 批量大小\n",
    "# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.4968 - accuracy: 0.7690\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.3121 - accuracy: 0.8685\n",
      "Epoch 3/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2575 - accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2173 - accuracy: 0.9156\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1831 - accuracy: 0.9312\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1505 - accuracy: 0.9447\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1167 - accuracy: 0.9582\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0890 - accuracy: 0.9693\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0680 - accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0520 - accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c357cfa580>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.Sequential(\n",
    "[\n",
    "keras.layers.Embedding(max_word_num,128,input_length=max_review_len),\n",
    "keras.layers.GRU(128,activation=\"tanh\"),\n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 1s 8ms/step - loss: 0.6117 - accuracy: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6116817593574524, 0.832772433757782]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "加入embedding 层后，进行了降维，词汇表的数量和句子的长度都能扩大，信息丢失的少。\n",
    "    \n",
    "测试的准确率也远远超过了模型1。\n",
    "    \n",
    "但训练集的准确率很高，存在过拟合现象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 尝试其他调参：学习率、优化器等，观察并讨论结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.5165 - accuracy: 0.7375\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.3369 - accuracy: 0.8591\n",
      "Epoch 3/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.2806 - accuracy: 0.8873\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.2495 - accuracy: 0.9013\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.2189 - accuracy: 0.9149\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.1943 - accuracy: 0.9261\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.1725 - accuracy: 0.9354\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.1539 - accuracy: 0.9439\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.1358 - accuracy: 0.9504\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 8s 40ms/step - loss: 0.1209 - accuracy: 0.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c3ebcbc5e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.Sequential(\n",
    "[\n",
    "keras.layers.Embedding(max_word_num,128,input_length=max_review_len),\n",
    "keras.layers.GRU(128,activation=\"tanh\",return_sequences=True, dropout=0.5),\n",
    "keras.layers.GRU(128,activation=\"tanh\", dropout=0.5),\n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(0.001),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 2s 13ms/step - loss: 0.3799 - accuracy: 0.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3798908293247223, 0.8568108677864075]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "在加入一层GRU，并且设置dropout=0.5后，测试集准确率提高了2个百分点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.尝试用预训练词嵌入作为模型 1 的输入，对比模型 4 的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_len = 120 # 句子最大长度s，大于的句子部分将截断，小于的将填充\n",
    "max_word_num=10000#词汇表数量\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_word_num)\n",
    "# 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "batchsz = 128 # 批量大小\n",
    "# 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "所用词向量数量及词向量矩阵形状： 9796 (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "embeddings_index = {}\n",
    "GLOVE_DIR = r'.\\glove.6B'\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "MAX_NUM_WORDS = max_word_num\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, 100))\n",
    "applied_vec_count = 0\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    # print(word,embedding_vector)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        applied_vec_count += 1\n",
    "print(\"所用词向量数量及词向量矩阵形状：\",applied_vec_count, embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.6635 - accuracy: 0.5840\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.4028 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2875 - accuracy: 0.8800\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2407 - accuracy: 0.9007\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2055 - accuracy: 0.9166\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 5s 26ms/step - loss: 0.1809 - accuracy: 0.9281\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1589 - accuracy: 0.9383\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1431 - accuracy: 0.9448\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1268 - accuracy: 0.9507\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1121 - accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cab3900d00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.Sequential(\n",
    "[\n",
    "keras.layers.Embedding(max_word_num,100,input_length=max_review_len,trainable=True,weights=[embedding_matrix]),\n",
    "keras.layers.GRU(128,activation=\"tanh\",dropout=0.5),\n",
    "keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(0.002),\n",
    "                  loss = losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(db_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/195 [..............................] - ETA: 0s - loss: 0.4006 - accuracy: 0.8672WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0050s). Check your callbacks.\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41843679547309875, 0.8627804517745972]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "    \n",
    "使用预训练的词向量加载Embedding层，可以发现训练的初期，在第3个epoch左右时，模型的准确率就已经很高了。\n",
    "    \n",
    "最终测试集的准确率也相比模型4提升了3个百分点。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
