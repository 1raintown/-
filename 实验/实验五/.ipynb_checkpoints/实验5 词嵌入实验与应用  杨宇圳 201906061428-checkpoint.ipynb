{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=center><font size = 5> <center>文本分析与挖掘</center> </font></h1> \n",
    "\n",
    "<h2 align=center><font size = 4><center>实验五、词嵌入实验与应用</center></font></h2>\n",
    "<h2 align=center><font size = 2><center>浙江工业大学计算机科学与技术学院</center></font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、实验目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li>实现两种基本词嵌入算法 skipgram 和 CBOW，并对结果进行对比和评估。</li>\n",
    "<li>掌握词嵌入在分类和聚类中的基本应用，了解预训练词嵌入的适用范围。</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验内容\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li>调用 gensim 得到词嵌入向量。</li>\n",
    "<li>基于词嵌入向量对 multi3 和 multi5 进行分类。</li>\n",
    "<li>预训练词向量</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.调用 gensim 得到词嵌入向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. 对 20newsgroups 子集 multi3 和 multi5 调用 gensim 得到skipgram 词嵌入向量。假设维度 100， 窗口大小：5。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "import itertools \n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "data=pd.read_csv('./data.csv')\n",
    "multi3_1=data[data['Target Name']=='comp.graphics'].sample(200)\n",
    "multi3_2=data[data['Target Name']=='rec.autos'].sample(200)\n",
    "multi3_3=data[data['Target Name']=='talk.politics.guns'].sample(200)\n",
    "\n",
    "multi3=multi3_1.append(multi3_2).append(multi3_3)\n",
    "\n",
    "\n",
    "multi5_1=data[data['Target Name']=='comp.graphics'].sample(200)\n",
    "multi5_2=data[data['Target Name']=='comp.windows.x'].sample(200)\n",
    "multi5_3=data[data['Target Name']=='rec.sport.hockey'].sample(200)\n",
    "multi5_4=data[data['Target Name']=='rec.autos'].sample(200)\n",
    "multi5_5=data[data['Target Name']=='talk.politics.guns'].sample(200)\n",
    "\n",
    "multi5=multi5_1.append(multi5_2).append(multi5_3).append(multi5_4).append(multi5_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去标点\n",
    "tokenized_corpus_3=[]\n",
    "clean_article=multi3['Clean Article'].tolist()\n",
    "for i in clean_article:\n",
    "    remove = str.maketrans('','',string.punctuation) \n",
    "    i = i.translate(remove)\n",
    "    a=word_tokenize(i)\n",
    "    tokenized_corpus_3.append(a)\n",
    "    \n",
    "tokenized_corpus_5=[]\n",
    "clean_article=multi5['Clean Article'].tolist()\n",
    "for i in clean_article:\n",
    "    remove = str.maketrans('','',string.punctuation) \n",
    "    i = i.translate(remove)\n",
    "    a=word_tokenize(i)\n",
    "    tokenized_corpus_5.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt= nltk.WordPunctTokenizer()\n",
    "\n",
    "feature_size=100\n",
    "window_context=5\n",
    "min_word_count=1\n",
    "sample=1e-3\n",
    "\n",
    "w2v_model_3=word2vec.Word2Vec(tokenized_corpus_3,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "\n",
    "w2v_model_5=word2vec.Word2Vec(tokenized_corpus_5,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_3.save('w2v_model_3.model')\n",
    "w2v_model_5.save('w2v_model_5.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_3 = KeyedVectors.load('w2v_model_3.model',mmap='r')\n",
    "w2v_model_5 = KeyedVectors.load('w2v_model_5.model',mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. 通过所含词的词向量取平均得到文档向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_vector3=[]\n",
    "article_vector5=[]\n",
    "for article in tokenized_corpus_3:\n",
    "    \n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "         continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_3.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    article_vector3.append(tmp.round(2))\n",
    "\n",
    "for article in tokenized_corpus_5:\n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_5.wv[word]   \n",
    "    tmp=tmp/len(article)\n",
    "    article_vector5.append(tmp.round(2))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. 基于以上文档向量，计算所有类每两个文档之间的欧式距离的平方做为该表示下类别的紧凑度 compactness，具体计算如下：![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi3有3类\n",
    "comp_3_1 = list(itertools.combinations(article_vector3[0:200], 2))\n",
    "comp_3_2 = list(itertools.combinations(article_vector3[200:400], 2))\n",
    "comp_3_3 = list(itertools.combinations(article_vector3[400:600], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi5有5类\n",
    "comp_5_1 = list(itertools.combinations(article_vector5[0:200], 2))\n",
    "comp_5_2 = list(itertools.combinations(article_vector5[200:400], 2))\n",
    "comp_5_3 = list(itertools.combinations(article_vector5[400:600], 2))\n",
    "comp_5_4 = list(itertools.combinations(article_vector5[600:800], 2))\n",
    "comp_5_5 = list(itertools.combinations(article_vector5[800:1000], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sum_3=0\n",
    "for i in comp_3_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3=dist+dist_sum_3\n",
    "for i in comp_3_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist\n",
    "for i in comp_3_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sum_5=0\n",
    "for i in comp_5_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_4:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_5:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "子集multi3紧凑度 compactness为 19811.55\n",
      "子集multi5紧凑度 compactness为 44940.47\n"
     ]
    }
   ],
   "source": [
    "print('子集multi3紧凑度 compactness为',dist_sum_3.round(2))\n",
    "print('子集multi5紧凑度 compactness为',dist_sum_5.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. 改变参数，对比 a 中得到 compactness。具体为：改变维度=200，窗口大小保持 5，重复上面实验;改变窗口大小 10，维度保持为 100，重复上面 skipgram 实验。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1)维度=200，窗口=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size=200\n",
    "window_context=5\n",
    "min_word_count=1\n",
    "sample=1e-3\n",
    "\n",
    "w2v_model_3=word2vec.Word2Vec(tokenized_corpus_3,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "\n",
    "w2v_model_5=word2vec.Word2Vec(tokenized_corpus_5,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "维度=200，窗口=5下 子集multi3紧凑度 compactness为 2991378.61\n",
      "维度=200，窗口=5下 子集multi5紧凑度 compactness为 10712186.67\n"
     ]
    }
   ],
   "source": [
    "article_vector3=[]\n",
    "article_vector5=[]\n",
    "for article in tokenized_corpus_3:\n",
    "    \n",
    "    tmp=np.empty(feature_size)\n",
    "    if len(article)==0:\n",
    "        article_vector3.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_3.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    article_vector3.append(tmp.round(2))\n",
    "\n",
    "for article in tokenized_corpus_5:\n",
    "    tmp=np.empty(feature_size)\n",
    "    if len(article)==0:\n",
    "        article_vector5.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_5.wv[word]   \n",
    "    tmp=tmp/len(article)\n",
    "    article_vector5.append(tmp.round(2))\n",
    "\n",
    "#multi3有3类\n",
    "comp_3_1 = list(itertools.combinations(article_vector3[0:200], 2))\n",
    "comp_3_2 = list(itertools.combinations(article_vector3[200:400], 2))\n",
    "comp_3_3 = list(itertools.combinations(article_vector3[400:600], 2))\n",
    "#multi5有5类\n",
    "comp_5_1 = list(itertools.combinations(article_vector5[0:200], 2))\n",
    "comp_5_2 = list(itertools.combinations(article_vector5[200:400], 2))\n",
    "comp_5_3 = list(itertools.combinations(article_vector5[400:600], 2))\n",
    "comp_5_4 = list(itertools.combinations(article_vector5[600:800], 2))\n",
    "comp_5_5 = list(itertools.combinations(article_vector5[800:1000], 2))\n",
    "\n",
    "dist_sum_3=0\n",
    "for i in comp_3_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3=dist+dist_sum_3\n",
    "for i in comp_3_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist\n",
    "for i in comp_3_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist\n",
    "\n",
    "dist_sum_5=0\n",
    "for i in comp_5_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_4:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_5:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "\n",
    "print('维度=200，窗口=5下 子集multi3紧凑度 compactness为',dist_sum_3.round(2))\n",
    "print('维度=200，窗口=5下 子集multi5紧凑度 compactness为',dist_sum_5.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2)维度=100，窗口=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "维度=100，窗口=10下 子集multi3紧凑度 compactness为 26210.23\n",
      "维度=100，窗口=10下 子集multi5紧凑度 compactness为 58072.73\n"
     ]
    }
   ],
   "source": [
    "feature_size=100\n",
    "window_context=10\n",
    "min_word_count=1\n",
    "sample=1e-3\n",
    "\n",
    "w2v_model_3=word2vec.Word2Vec(tokenized_corpus_3,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "\n",
    "w2v_model_5=word2vec.Word2Vec(tokenized_corpus_5,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "\n",
    "article_vector3=[]\n",
    "article_vector5=[]\n",
    "for article in tokenized_corpus_3:\n",
    "    \n",
    "    tmp=np.empty(feature_size)\n",
    "    if len(article)==0:\n",
    "        article_vector3.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_3.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    article_vector3.append(tmp.round(2))\n",
    "\n",
    "for article in tokenized_corpus_5:\n",
    "    tmp=np.empty(feature_size)\n",
    "    if len(article)==0:\n",
    "        article_vector5.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_5.wv[word]   \n",
    "    tmp=tmp/len(article)\n",
    "    article_vector5.append(tmp.round(2))\n",
    "\n",
    "#multi3有3类\n",
    "comp_3_1 = list(itertools.combinations(article_vector3[0:200], 2))\n",
    "comp_3_2 = list(itertools.combinations(article_vector3[200:400], 2))\n",
    "comp_3_3 = list(itertools.combinations(article_vector3[400:600], 2))\n",
    "#multi5有5类\n",
    "comp_5_1 = list(itertools.combinations(article_vector5[0:200], 2))\n",
    "comp_5_2 = list(itertools.combinations(article_vector5[200:400], 2))\n",
    "comp_5_3 = list(itertools.combinations(article_vector5[400:600], 2))\n",
    "comp_5_4 = list(itertools.combinations(article_vector5[600:800], 2))\n",
    "comp_5_5 = list(itertools.combinations(article_vector5[800:1000], 2))\n",
    "\n",
    "dist_sum_3=0\n",
    "for i in comp_3_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3=dist+dist_sum_3\n",
    "for i in comp_3_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist\n",
    "for i in comp_3_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist\n",
    "\n",
    "dist_sum_5=0\n",
    "for i in comp_5_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_4:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_5:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "\n",
    "print('维度=100，窗口=10下 子集multi3紧凑度 compactness为',dist_sum_3.round(2))\n",
    "print('维度=100，窗口=10下 子集multi5紧凑度 compactness为',dist_sum_5.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "查看三次实验结果可以发现，增大维度和滑动窗口都会使紧凑度的数值增加，且增加滑动窗口造成的紧凑度数值上升较小，而扩大维度，会使紧凑度增加的特别大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. 按照 a 中参数设置，调用 gensim 实现 CBOW 词向量嵌入，计算Compactness,对比同样参数设置下 skipgram 的结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW方式子集multi3紧凑度 compactness为 30207.92\n",
      "CBOW方式子集multi5紧凑度 compactness为 107117.07\n"
     ]
    }
   ],
   "source": [
    "wpt= nltk.WordPunctTokenizer()\n",
    "\n",
    "feature_size=100\n",
    "window_context=5\n",
    "min_word_count=1\n",
    "sample=1e-3\n",
    "\n",
    "w2v_model_3=word2vec.Word2Vec(tokenized_corpus_3,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=0)\n",
    "\n",
    "w2v_model_5=word2vec.Word2Vec(tokenized_corpus_5,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=0)\n",
    "\n",
    "#获取文档向量\n",
    "article_vector3=[]\n",
    "article_vector5=[]\n",
    "for article in tokenized_corpus_3:\n",
    "    tmp=np.empty(feature_size)\n",
    "    if len(article)==0:\n",
    "        article_vector3.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_3.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    article_vector3.append(tmp.round(2))\n",
    "\n",
    "for article in tokenized_corpus_5:\n",
    "    tmp=np.empty(feature_size)\n",
    "    if len(article)==0:\n",
    "        article_vector5.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_5.wv[word]   \n",
    "    tmp=tmp/len(article)\n",
    "    article_vector5.append(tmp.round(2))\n",
    "\n",
    "#multi3有3类\n",
    "comp_3_1 = list(itertools.combinations(article_vector3[0:200], 2))\n",
    "comp_3_2 = list(itertools.combinations(article_vector3[200:400], 2))\n",
    "comp_3_3 = list(itertools.combinations(article_vector3[400:600], 2))\n",
    "#multi5有5类\n",
    "comp_5_1 = list(itertools.combinations(article_vector5[0:200], 2))\n",
    "comp_5_2 = list(itertools.combinations(article_vector5[200:400], 2))\n",
    "comp_5_3 = list(itertools.combinations(article_vector5[400:600], 2))\n",
    "comp_5_4 = list(itertools.combinations(article_vector5[600:800], 2))\n",
    "comp_5_5 = list(itertools.combinations(article_vector5[800:1000], 2))\n",
    "\n",
    "dist_sum_3=0\n",
    "for i in comp_3_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3=dist+dist_sum_3\n",
    "for i in comp_3_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist\n",
    "for i in comp_3_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_3+=dist\n",
    "\n",
    "dist_sum_5=0\n",
    "for i in comp_5_1:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_2:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_3:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_4:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "for i in comp_5_5:\n",
    "    dist = np.linalg.norm(i[0] -i[1])\n",
    "    dist_sum_5+=dist\n",
    "\n",
    "print('CBOW方式子集multi3紧凑度 compactness为',dist_sum_3.round(2))\n",
    "print('CBOW方式子集multi5紧凑度 compactness为',dist_sum_5.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "使用skipgram方式得到的紧凑度分别为19811.55和44940.47。\n",
    "    \n",
    "可以发现CBOW词向量方式的紧凑度要比skipgram大，接近两倍左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. 基于 sklearn 中的 TSNE 工具，进行可视化。具体用法参考课件例子。基于 skip-learn 和 TFIDF 用 TSNE 画出 2 维词嵌入结果并讨论。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "similar_words={search_term:[item[0]\n",
    "              for item in w2v_model_3.wv.most_similar([search_term],topn=5)]\n",
    "                  for search_term in['god','water','man','woman']}\n",
    "words=sum([[k]+v for k,v in similar_words.items()],[])\n",
    "wvs=w2v_model_3.wv[words]\n",
    "tsne=TSNE(n_components=2,random_state=42,n_iter=10000,perplexity=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "T=tsne.fit_transform(wvs)\n",
    "labels=words\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.scatter(T[:,0],T[:,1],c='orange',edgecolors='r')\n",
    "for label,x,y in zip(labels,T[:,0],T[:,1]):\n",
    "    plt.annotate(label,xy=(x+1,y+1),xytext=(0,0),textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.基于词嵌入向量对 multi3 和 multi5 进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. 基于词嵌入向量（设定适当参数，文档向量为其所含词的词嵌入向量的平均），用 SVM 进行分类，得到 accuracy。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size=100\n",
    "window_context=5\n",
    "min_word_count=1\n",
    "sample=1e-3\n",
    "\n",
    "#去标点\n",
    "tokenized_corpus_3=[]\n",
    "clean_article=multi3['Clean Article'].tolist()\n",
    "for i in clean_article:\n",
    "    remove = str.maketrans('','',string.punctuation) \n",
    "    i = i.translate(remove)\n",
    "    a=word_tokenize(i)\n",
    "    text=' '.join(a)\n",
    "    tokenized_corpus_3.append(text)\n",
    "multi3['Clean Article remove punc']= tokenized_corpus_3\n",
    "\n",
    "tokenized_corpus_5=[]\n",
    "clean_article=multi5['Clean Article'].tolist()\n",
    "for i in clean_article:\n",
    "    remove = str.maketrans('','',string.punctuation) \n",
    "    i = i.translate(remove)\n",
    "    a=word_tokenize(i)\n",
    "    text=' '.join(a)\n",
    "    tokenized_corpus_5.append(text)\n",
    "multi5['Clean Article remove punc']= tokenized_corpus_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1)multi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi3 Accuracy (5-fold): [0.65432099 0.64197531 0.675      0.575      0.5625    ]\n",
      "multi3 Mean Accuracy: 0.6217592592592592\n",
      "multi3 Test Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "wpt= nltk.WordPunctTokenizer()\n",
    "\n",
    "feature_size=100\n",
    "window_context=5\n",
    "min_word_count=1\n",
    "sample=1e-3\n",
    "\n",
    "w2v_model_3=word2vec.Word2Vec(tokenized_corpus_3,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "article_vector3=[]\n",
    "for article in tokenized_corpus_3: \n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "        article_vector3.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_3.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    article_vector3.append(tmp.round(2))\n",
    "\n",
    "\n",
    "train_features,test_features,train_label_names,test_label_names = train_test_split(np.array(article_vector3)\n",
    "                                                                        ,np.array(multi3['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "svm = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm.fit(train_features, train_label_names)\n",
    "svm_bow_scores = cross_val_score(svm,train_features,train_label_names,cv=5)\n",
    "svm_bow_mean_score = np.mean(svm_bow_scores)\n",
    "print('multi3 Accuracy (5-fold):',svm_bow_scores)\n",
    "print('multi3 Mean Accuracy:', svm_bow_mean_score)\n",
    "svm_bow_test_score = svm.score(test_features, test_label_names)\n",
    "print('multi3 Test Accuracy:', svm_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2)multi5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi5 Accuracy (5-fold): [0.58955224 0.57462687 0.56716418 0.52238806 0.57462687]\n",
      "multi5 Mean Accuracy: 0.5656716417910448\n",
      "multi5 Test Accuracy: 0.5757575757575758\n"
     ]
    }
   ],
   "source": [
    "wpt= nltk.WordPunctTokenizer()\n",
    "\n",
    "feature_size=100\n",
    "window_context=5\n",
    "min_word_count=1\n",
    "sample=1e-3\n",
    "\n",
    "w2v_model_5=word2vec.Word2Vec(tokenized_corpus_5,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "article_vector5=[]\n",
    "for article in tokenized_corpus_5: \n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "        article_vector5.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_5.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    article_vector5.append(tmp.round(2))\n",
    "\n",
    "\n",
    "train_features,test_features,train_label_names,test_label_names = train_test_split(np.array(article_vector5)\n",
    "                                                                        ,np.array(multi5['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "svm = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm.fit(train_features, train_label_names)\n",
    "svm_bow_scores = cross_val_score(svm,train_features,train_label_names,cv=5)\n",
    "svm_bow_mean_score = np.mean(svm_bow_scores)\n",
    "print('multi5 Accuracy (5-fold):',svm_bow_scores)\n",
    "print('multi5 Mean Accuracy:', svm_bow_mean_score)\n",
    "svm_bow_test_score = svm.score(test_features, test_label_names)\n",
    "print('multi5 Test Accuracy:', svm_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果展示：\n",
    "    \n",
    "对于multl3,词嵌入下svm的测试集准确率有0.67\n",
    "    \n",
    "对于multl5,词嵌入下svm的测试集准确率只有0.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. 基于 TFIDF 词袋模型用 SVM 对上面两个数据集进行分类，对比a 中结果并讨论。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi3 TV Accuracy (5-fold): [0.91358025 0.91358025 0.925      0.9        0.9       ]\n",
      "multi3 Mean TV Accuracy: 0.9104320987654321\n",
      "multi3 Test Accuracy: 0.8787878787878788\n",
      "\n",
      "multi5 TV Accuracy (5-fold): [0.86567164 0.82835821 0.82835821 0.88059701 0.84328358]\n",
      "multi5 Mean TV Accuracy: 0.8492537313432835\n",
      "multi5 Test Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "#multi3\n",
    "train_corpus,test_corpus,train_label_names,test_label_names = train_test_split(np.array(multi3['Clean Article'])\n",
    "                                                                        ,np.array(multi3['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "svm = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_bow_tv_scores = cross_val_score(svm,tv_train_features,train_label_names,cv=5)\n",
    "svm_bow_tv_mean_score = np.mean(svm_bow_tv_scores)\n",
    "print('multi3 TV Accuracy (5-fold):',svm_bow_tv_scores)\n",
    "print('multi3 Mean TV Accuracy:', svm_bow_tv_mean_score)\n",
    "svm_bow_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('multi3 Test Accuracy:', svm_bow_test_score)\n",
    "print()\n",
    "\n",
    "#multi5\n",
    "train_corpus,test_corpus,train_label_names,test_label_names = train_test_split(np.array(multi5['Clean Article'])\n",
    "                                                                        ,np.array(multi5['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "svm = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_bow_tv_scores = cross_val_score(svm,tv_train_features,train_label_names,cv=5)\n",
    "svm_bow_tv_mean_score = np.mean(svm_bow_tv_scores)\n",
    "print('multi5 TV Accuracy (5-fold):',svm_bow_tv_scores)\n",
    "print('multi5 Mean TV Accuracy:', svm_bow_tv_mean_score)\n",
    "svm_bow_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('multi5 Test Accuracy:', svm_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果展示：\n",
    "    \n",
    "对于multl3,TFIDF的测试集准确率有0.88\n",
    "    \n",
    "对于multl5,TFIDF的测试集准确率有0.87\n",
    "\n",
    "两个结果都远远超过了用词嵌入方法得到的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. 把两种表示拼接起来得到新的文档表示后进行 SVM 分类，对比结果并讨论。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi3 Accuracy (5-fold): [0.88888889 0.90123457 0.875      0.9        0.85      ]\n",
      "multi3 Mean Accuracy: 0.8830246913580246\n",
      "multi3 Test Accuracy: 0.8434343434343434\n",
      "multi5 Accuracy (5-fold): [0.82835821 0.79104478 0.79104478 0.88059701 0.85074627]\n",
      "multi5 Mean Accuracy: 0.8283582089552238\n",
      "multi5 Test Accuracy: 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "#multi3\n",
    "train_corpus,test_corpus,train_label_names,test_label_names = train_test_split(np.array(multi3['Clean Article remove punc'])\n",
    "                                                                        ,np.array(multi3['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "\n",
    "\n",
    "\n",
    "train_words=[word_tokenize(i) for i in train_corpus ]\n",
    "test_words=[word_tokenize(i) for i in test_corpus ]\n",
    "\n",
    "w2v_model_3=word2vec.Word2Vec(train_words+test_words,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "\n",
    "\n",
    "train_article_vector3=[]\n",
    "for article in train_words: \n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "        train_article_vector3.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_3.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    train_article_vector3.append(tmp.round(2))\n",
    "    \n",
    "test_article_vector3=[]\n",
    "for article in test_words: \n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "        test_article_vector3.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_3.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    test_article_vector3.append(tmp.round(2))\n",
    "\n",
    "train_features=[]\n",
    "test_features=[]\n",
    "for i in range(len(train_article_vector3)):\n",
    "    train_features.append(np.hstack((train_article_vector3[i],tv_train_features.toarray()[i])))\n",
    "for i in range(len(test_article_vector3)):\n",
    "    test_features.append(np.hstack((test_article_vector3[i],tv_test_features.toarray()[i])))  \n",
    "    \n",
    "svm = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm.fit(train_features, train_label_names)\n",
    "svm_bow_scores = cross_val_score(svm,train_features,train_label_names,cv=5)\n",
    "svm_bow_mean_score = np.mean(svm_bow_scores)\n",
    "print('multi3 Accuracy (5-fold):',svm_bow_scores)\n",
    "print('multi3 Mean Accuracy:', svm_bow_mean_score)\n",
    "svm_bow_test_score = svm.score(test_features, test_label_names)\n",
    "print('multi3 Test Accuracy:', svm_bow_test_score)\n",
    "\n",
    "#multi5\n",
    "train_corpus,test_corpus,train_label_names,test_label_names = train_test_split(np.array(multi5['Clean Article remove punc'])\n",
    "                                                                        ,np.array(multi5['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "\n",
    "\n",
    "\n",
    "train_words=[word_tokenize(i) for i in train_corpus ]\n",
    "test_words=[word_tokenize(i) for i in test_corpus ]\n",
    "\n",
    "w2v_model_5=word2vec.Word2Vec(train_words+test_words,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)\n",
    "\n",
    "\n",
    "train_article_vector5=[]\n",
    "for article in train_words: \n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "        train_article_vector5.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_5.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    train_article_vector5.append(tmp.round(2))\n",
    "    \n",
    "test_article_vector5=[]\n",
    "for article in test_words: \n",
    "    tmp=np.empty(100)\n",
    "    if len(article)==0:\n",
    "        test_article_vector5.append(tmp.round(2))\n",
    "        continue\n",
    "    for word in article:\n",
    "        tmp=tmp+w2v_model_5.wv[word]\n",
    "    tmp=tmp/len(article)\n",
    "    test_article_vector5.append(tmp.round(2))\n",
    "\n",
    "train_features=[]\n",
    "test_features=[]\n",
    "for i in range(len(train_article_vector5)):\n",
    "    train_features.append(np.hstack((train_article_vector5[i],tv_train_features.toarray()[i])))\n",
    "for i in range(len(test_article_vector5)):\n",
    "    test_features.append(np.hstack((test_article_vector5[i],tv_test_features.toarray()[i])))  \n",
    "    \n",
    "svm = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm.fit(train_features, train_label_names)\n",
    "svm_bow_scores = cross_val_score(svm,train_features,train_label_names,cv=5)\n",
    "svm_bow_mean_score = np.mean(svm_bow_scores)\n",
    "print('multi5 Accuracy (5-fold):',svm_bow_scores)\n",
    "print('multi5 Mean Accuracy:', svm_bow_mean_score)\n",
    "svm_bow_test_score = svm.score(test_features, test_label_names)\n",
    "print('multi5 Test Accuracy:', svm_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "    \n",
    "对于multi3和multi5这两数据集，将两种表示拼接后得到的测试集准确率为0.85和0.86，比使用词嵌入方法的方式高，但较于TFIDF的方法，准确率却有略微的降低，能体现出拼接后，平均文档向量会一定程度上干扰判断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. 以 TFIDF 为权重，对每个文档所含词向量进行加权平均得到文档向量，进行 SVM 分类，对比前面结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算权重平均文档向量函数\n",
    "def tfidf_wtd_avg_word_vectors(words,tfidf_vector,tfidf_vocabulary,model,num_features):\n",
    "    word_tfidfs=[tfidf_vector[0,tfidf_vocabulary.get(word)] if tfidf_vocabulary.get(word) else 0 for word in words]\n",
    "    word_tfidf_map={word:tfidf_val for word,tfidf_val in zip(words,word_tfidfs)}\n",
    "    feature_vector=np.zeros((num_features,),dtype='float64')\n",
    "    vocabulary=set(model.wv.index_to_key)\n",
    "    wts=0\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            word_vector=model.wv[word]\n",
    "            weighted_word_vector=word_tfidf_map[word]*word_vector\n",
    "            wts=wts+word_tfidf_map[word]\n",
    "            feature_vector=np.add(feature_vector,weighted_word_vector)\n",
    "    if wts:\n",
    "        feature_vector=np.divide(feature_vector,wts)\n",
    "    return feature_vector\n",
    "\n",
    "def tfidf_weighted_averaged_word_vectorizer(corpus,tfidf_vectors,tfidf_vocabulary,model,num_features):\n",
    "    docs_tfidfs=[(doc,doc_tfidf) for doc,doc_tfidf in zip(corpus,tfidf_vectors)]\n",
    "    features=[tfidf_wtd_avg_word_vectors(tokenized_sentence,tfidf,tfidf_vocabulary,model,num_features) for tokenized_sentence,tfidf in docs_tfidfs]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi3\n",
    "train_corpus_3,test_corpus_3,train_label_names_3,test_label_names_3 = train_test_split(np.array(multi3['Clean Article remove punc'])\n",
    "                                                                        ,np.array(multi3['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "\n",
    "tv_3 = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features_3=tv_3.fit_transform(train_corpus_3)\n",
    "tv_test_features_3=tv_3.fit_transform(test_corpus_3)\n",
    "\n",
    "\n",
    "train_words_3=[word_tokenize(i) for i in train_corpus_3 ]\n",
    "test_words_3=[word_tokenize(i) for i in test_corpus_3 ]\n",
    "\n",
    "w2v_model_3=word2vec.Word2Vec(train_words_3+test_words_3,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi5\n",
    "train_corpus_5,test_corpus_5,train_label_names_5,test_label_names_5 = train_test_split(np.array(multi5['Clean Article remove punc'])\n",
    "                                                                        ,np.array(multi5['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "\n",
    "tv_5 = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features_5=tv_5.fit_transform(train_corpus_5)\n",
    "tv_test_features_5=tv_5.fit_transform(test_corpus_5)\n",
    "\n",
    "\n",
    "train_words_5=[word_tokenize(i) for i in train_corpus_5 ]\n",
    "test_words_5=[word_tokenize(i) for i in test_corpus_5 ]\n",
    "\n",
    "w2v_model_5=word2vec.Word2Vec(train_words_5+test_words_5,\n",
    "                              vector_size=feature_size,\n",
    "                              window=window_context,\n",
    "                           min_count=min_word_count,\n",
    "                              sample=sample,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_3_voca=tv_3.vocabulary_\n",
    "train_features_3=tfidf_weighted_averaged_word_vectorizer(train_words_3,tv_train_features_3,tv_3_voca,w2v_model_3,100)\n",
    "test_features_3=tfidf_weighted_averaged_word_vectorizer(test_words_3,tv_test_features_3,tv_3_voca,w2v_model_3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_5_voca=tv_5.vocabulary_\n",
    "train_features_5=tfidf_weighted_averaged_word_vectorizer(train_words_5,tv_train_features_5,tv_5_voca,w2v_model_5,100)\n",
    "test_features_5=tfidf_weighted_averaged_word_vectorizer(test_words_5,tv_test_features_5,tv_5_voca,w2v_model_5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi3 Test Accuracy: 0.667\n",
      "multi5 Test Accuracy: 0.712\n"
     ]
    }
   ],
   "source": [
    "svm_3 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_3.fit(train_features_3, train_label_names_3)\n",
    "svm_bow_test_score_3 = svm_3.score(test_features_3, test_label_names_3)\n",
    "print('multi3 Test Accuracy:', svm_bow_test_score_3.round(3))\n",
    "\n",
    "svm_5 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_5.fit(train_features_5, train_label_names_5)\n",
    "svm_bow_test_score_5 = svm_5.score(test_features_5, test_label_names_5)\n",
    "print('multi5 Test Accuracy:', svm_bow_test_score_5.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "    \n",
    "对每个文档所含词向量进行加权平均得到文档向量操作后，分类的准确度比单纯使用词向量和词向量与TFIDF拼接的效果都要好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.预训练词向量 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于 Glove 预训练词向量，重复上面 a,c,d 中的实验，根据结果讨论预训练词向量的适用范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-11c819397eb6>:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  (count, dimensions) = glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193514 \n",
      " 50\n"
     ]
    }
   ],
   "source": [
    "glove_input_file = 'glove.twitter.27B/glove.twitter.27B.50d.txt'\n",
    "word2vec_output_file = 'glove.twitter.27B/glove.twitter.27B..word2vec.txt'\n",
    "(count, dimensions) = glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "print(count, '\\n', dimensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.8646e-01 -3.4356e-01 -3.0380e-01 -2.2574e-01 -8.3226e-01 -5.0343e-01\n",
      "  5.5678e-01  1.5743e-01  8.8370e-02  1.4789e-01 -1.6460e-01  6.6234e-01\n",
      " -3.7069e+00 -1.8796e-01  2.5459e-04  5.1017e-01  3.0290e-01 -1.1149e+00\n",
      "  3.2269e-01 -2.3953e-01 -6.4404e-01  2.7223e-01  2.4307e-01 -2.7370e-01\n",
      " -1.1198e-01  4.2510e-01 -9.2354e-01  2.3444e-01  5.3379e-01  2.2733e-01\n",
      " -5.1808e-01  3.2424e-01  3.9646e-01 -5.5740e-01 -4.9668e-01 -6.1077e-02\n",
      "  2.3813e-01 -3.3908e-01  3.1550e-01 -3.6068e-01 -1.2946e+00 -1.5165e-01\n",
      " -8.9922e-01  4.0949e-01  6.3683e-01  1.1439e+00  7.2612e-01  2.4406e-01\n",
      " -3.1790e-01 -6.0281e-01]\n",
      "[('squirrel', 0.8802487254142761), ('monkey', 0.8800931572914124), ('lizard', 0.8797428607940674), ('unicorn', 0.8575026392936707), ('turtle', 0.8562190532684326), ('rabbit', 0.8355662822723389), ('elephant', 0.8345798850059509), ('dinosaur', 0.8336232304573059), ('toad', 0.8300161957740784), ('bunny', 0.8233627080917358)]\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "# 如果希望直接获取某个单词的向量表示，直接以下标方式访问即可\n",
    "cat_vec = glove_model['cat']\n",
    "print(cat_vec)\n",
    "# 获得单词frog的最相似向量的词汇\n",
    "print(glove_model.most_similar('frog'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. 基于词嵌入向量（设定适当参数，文档向量为其所含词的词嵌入向量的平均），用 SVM 进行分类，得到 accuracy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取平均文档向量\n",
    "def average_word_vectors(words,model,vocabulary,num_features):\n",
    "    feature_vector=np.zeros((num_features,),dtype='float64')\n",
    "    nwords=0\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            nwords=nwords+1\n",
    "            feature_vector=np.add(feature_vector,model[word])\n",
    "    if nwords:\n",
    "        feature_vector=np.divide(feature_vector,nwords)\n",
    "    return feature_vector\n",
    "\n",
    "def averaged_word_vectorizer(corpus,model,num_features):\n",
    "    #get the all vocabulary\n",
    "    vocabulary=set(model.index_to_key)\n",
    "    features=[average_word_vectors(tokenized_sentence,model,vocabulary,num_features) for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_3,test_corpus_3,train_label_names_3,test_label_names_3 = train_test_split(np.array(multi3['Clean Article remove punc'])\n",
    "                                                                        ,np.array(multi3['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)\n",
    "train_corpus_5,test_corpus_5,train_label_names_5,test_label_names_5 = train_test_split(np.array(multi5['Clean Article remove punc'])\n",
    "                                                                        ,np.array(multi5['Target Name'])\n",
    "                                                                        ,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi3 Test Accuracy: 0.556\n",
      "multi5 Test Accuracy: 0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\app\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "train_features_3=averaged_word_vectorizer(train_corpus_3,model=glove_model,num_features=50)\n",
    "test_features_3=averaged_word_vectorizer(test_corpus_3,model=glove_model,num_features=50)\n",
    "\n",
    "train_features_5=averaged_word_vectorizer(train_corpus_5,model=glove_model,num_features=50)\n",
    "test_features_5=averaged_word_vectorizer(test_corpus_5,model=glove_model,num_features=50)\n",
    "\n",
    "svm_3 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_3.fit(train_features_3, train_label_names_3)\n",
    "svm_bow_test_score_3 = svm_3.score(test_features_3, test_label_names_3)\n",
    "print('multi3 Test Accuracy:', svm_bow_test_score_3.round(3))\n",
    "\n",
    "svm_5 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_5.fit(train_features_5, train_label_names_5)\n",
    "svm_bow_test_score_5 = svm_5.score(test_features_5, test_label_names_5)\n",
    "print('multi5 Test Accuracy:', svm_bow_test_score_5.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. 把两种表示拼接起来得到新的文档表示后进行 SVM 分类，对比结果并讨论。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_3 = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features_3=tv_3.fit_transform(train_corpus_3)\n",
    "tv_test_features_3=tv_3.transform(test_corpus_3)\n",
    "\n",
    "\n",
    "tv_5 = TfidfVectorizer(min_df=0.0, max_df=1.0, norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_train_features_5=tv_5.fit_transform(train_corpus_5)\n",
    "tv_test_features_5=tv_5.transform(test_corpus_5)\n",
    "\n",
    "\n",
    "new_train_features_3=[]\n",
    "new_test_features_3=[]\n",
    "for i in range(len(train_features_3)):\n",
    "    new_train_features_3.append(np.hstack((train_features_3[i],tv_train_features_3.toarray()[i])))\n",
    "for i in range(len(test_features_3)):\n",
    "    new_test_features_3.append(np.hstack((test_features_3[i],tv_test_features_3.toarray()[i])))  \n",
    "    \n",
    "new_train_features_5=[]\n",
    "new_test_features_5=[]\n",
    "for i in range(len(train_features_5)):\n",
    "    new_train_features_5.append(np.hstack((train_features_5[i],tv_train_features_5.toarray()[i])))\n",
    "for i in range(len(test_features_5)):\n",
    "    new_test_features_5.append(np.hstack((test_features_5[i],tv_test_features_5.toarray()[i])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi3 Test Accuracy: 0.869\n",
      "multi5 Test Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "svm_3 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_3.fit(new_train_features_3, train_label_names_3)\n",
    "svm_bow_test_score_3 = svm_3.score(new_test_features_3, test_label_names_3)\n",
    "print('multi3 Test Accuracy:', svm_bow_test_score_3.round(3))\n",
    "\n",
    "svm_5 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_5.fit(new_train_features_5, train_label_names_5)\n",
    "svm_bow_test_score_5 = svm_5.score(new_test_features_5, test_label_names_5)\n",
    "print('multi5 Test Accuracy:', svm_bow_test_score_5.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. 以 TFIDF 为权重，对每个文档所含词向量进行加权平均得到文档向量，进行 SVM 分类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算权重平均文档向量函数\n",
    "def tfidf_wtd_avg_word_vectors(words,tfidf_vector,tfidf_vocabulary,model,num_features):\n",
    "    word_tfidfs=[tfidf_vector[0,tfidf_vocabulary.get(word)] if tfidf_vocabulary.get(word) else 0 for word in words]\n",
    "    word_tfidf_map={word:tfidf_val for word,tfidf_val in zip(words,word_tfidfs)}\n",
    "    feature_vector=np.zeros((num_features,),dtype='float64')\n",
    "    vocabulary=set(model.index_to_key)\n",
    "    wts=0\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            word_vector=model[word]\n",
    "            weighted_word_vector=word_tfidf_map[word]*word_vector\n",
    "            wts=wts+word_tfidf_map[word]\n",
    "            feature_vector=np.add(feature_vector,weighted_word_vector)\n",
    "    if wts:\n",
    "        feature_vector=np.divide(feature_vector,wts)\n",
    "    return feature_vector\n",
    "\n",
    "def tfidf_weighted_averaged_word_vectorizer(corpus,tfidf_vectors,tfidf_vocabulary,model,num_features):\n",
    "    docs_tfidfs=[(doc,doc_tfidf) for doc,doc_tfidf in zip(corpus,tfidf_vectors)]\n",
    "    features=[tfidf_wtd_avg_word_vectors(tokenized_sentence,tfidf,tfidf_vocabulary,model,num_features) for tokenized_sentence,tfidf in docs_tfidfs]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_3=tv_3.vocabulary_\n",
    "\n",
    "vocabulary_5=tv_5.vocabulary_\n",
    "\n",
    "train_words_3=[word_tokenize(i) for i in train_corpus_3 ]\n",
    "test_words_3=[word_tokenize(i) for i in test_corpus_3 ]\n",
    "\n",
    "train_words_5=[word_tokenize(i) for i in train_corpus_5 ]\n",
    "test_words_5=[word_tokenize(i) for i in test_corpus_5 ]\n",
    "\n",
    "\n",
    "train_features_3=tfidf_weighted_averaged_word_vectorizer(train_words_3,tv_train_features_3,vocabulary_3,glove_model,50)\n",
    "test_features_3=tfidf_weighted_averaged_word_vectorizer(test_words_3,tv_test_features_3,vocabulary_3,glove_model,50)\n",
    "\n",
    "train_features_5=tfidf_weighted_averaged_word_vectorizer(train_words_5,tv_train_features_5,vocabulary_5,glove_model,50)\n",
    "test_features_5=tfidf_weighted_averaged_word_vectorizer(test_words_5,tv_test_features_5,vocabulary_5,glove_model,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi3 Test Accuracy: 0.758\n",
      "multi5 Test Accuracy: 0.727\n"
     ]
    }
   ],
   "source": [
    "svm_3 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_3.fit(train_features_3, train_label_names_3)\n",
    "svm_bow_test_score_3 = svm_3.score(test_features_3, test_label_names_3)\n",
    "print('multi3 Test Accuracy:', svm_bow_test_score_3.round(3))\n",
    "\n",
    "svm_5 = LinearSVC(penalty='l2',C=1,random_state=42)  # SVM模型\n",
    "svm_5.fit(train_features_5, train_label_names_5)\n",
    "svm_bow_test_score_5 = svm_5.score(test_features_5, test_label_names_5)\n",
    "print('multi5 Test Accuracy:', svm_bow_test_score_5.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 10px\">\n",
    "结果分析和讨论：\n",
    "\n",
    "使用预训练的词向量后，预测的准确率都要较好于用自己的数据集训练出来的词向量，对于数据量较小的multi3，提升较明显；而对于multi5，准确率提升的不是特别大。\n",
    "\n",
    "由此可见，当自己拥有的数据集的规模较大时，可以不考虑使用预训练的词向量。\n",
    "    \n",
    "若数据集较少，且预训练的词向量内容与自己的数据相关度较高时，可以考虑使用预训练的词向量"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
