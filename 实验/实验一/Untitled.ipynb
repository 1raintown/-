{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.1.3-cp38-cp38-win_amd64.whl (12.0 MB)\n",
      "Requirement already satisfied: setuptools in d:\\app\\anaconda\\lib\\site-packages (from spacy) (50.3.1.post20201107)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\app\\anaconda\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\app\\anaconda\\lib\\site-packages (from spacy) (20.4)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp38-cp38-win_amd64.whl (21 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp38-cp38-win_amd64.whl (6.5 MB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\app\\anaconda\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: jinja2 in d:\\app\\anaconda\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp38-cp38-win_amd64.whl (451 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp38-cp38-win_amd64.whl (112 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.9\n",
      "  Downloading thinc-8.0.10-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\app\\anaconda\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Requirement already satisfied: six in d:\\app\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\app\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\app\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\app\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\app\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\app\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\app\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\app\\anaconda\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\app\\anaconda\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-legacy, pathy, spacy\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.6 cymem-2.0.5 murmurhash-1.0.5 pathy-0.6.0 preshed-3.0.5 pydantic-1.8.2 smart-open-5.2.1 spacy-3.1.3 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.10 typer-0.4.0 wasabi-0.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"D:\\app\\anaconda\\lib\\http\\client.py\", line 458, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"D:\\app\\anaconda\\lib\\http\\client.py\", line 502, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"D:\\app\\anaconda\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"D:\\app\\anaconda\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"D:\\app\\anaconda\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 164, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 204, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\commands\\install.py\", line 338, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 482, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 349, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 201, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 281, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 225, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 292, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 481, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 526, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 213, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 94, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"D:\\app\\anaconda\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install D:\\app\\anaconda\\en_core_web_sm-2.3.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'m\", 'tim', ',', 'how', 'jumping', 'you', '?']\n",
      "['i', \"'m\", 'tim', ',', 'how', 'jump', 'you', '?']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl=WordNetLemmatizer()\n",
    "\n",
    "ps=PorterStemmer()\n",
    "default_wt=nltk.word_tokenize\n",
    "\n",
    "text=\"\"\"i'm tim ,how jumping you?\"\"\"\n",
    "words=default_wt(text)\n",
    "print(words)\n",
    "stem=[ps.stem(i) for i in words]\n",
    "print(stem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'degre'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(wnl.lemmatize('running','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['footbal', 'is', 'a', 'famili', 'of', 'team', 'sport', 'that', 'involv', ',', 'to', 'vari', 'degre', ',', 'kick', 'a', 'ball', 'to', 'score', 'a', 'goal', '.']\n",
      "[('footbal', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('famili', 'NN'), ('of', 'IN'), ('team', 'NN'), ('sport', 'NN'), ('that', 'WDT'), ('involv', 'NN'), (',', ','), ('to', 'TO'), ('vari', 'VB'), ('degre', 'NN'), (',', ','), ('kick', 'VB'), ('a', 'DT'), ('ball', 'NN'), ('to', 'TO'), ('score', 'VB'), ('a', 'DT'), ('goal', 'NN'), ('.', '.')]\n",
      "['footbal', 'be', 'a', 'famili', 'of', 'team', 'sport', 'that', 'involv', ',', 'to', 'vari', 'degre', ',', 'kick', 'a', 'ball', 'to', 'score', 'a', 'goal', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps=PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# 获取单词的词性\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "sentence = 'football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.'\n",
    "tokens = word_tokenize(sentence)  # 分词\n",
    "stem=[ps.stem(i) for i in tokens] #词干提取\n",
    "print(stem)\n",
    "tagged_sent = pos_tag(stem)     # 获取单词词性\n",
    "\n",
    "print(tagged_sent)\n",
    "lemmas_sent = []\n",
    "for tag in tagged_sent:\n",
    "    wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "    lemmas_sent.append(wnl.lemmatize(tag[0], pos=wordnet_pos)) # 词形还原\n",
    "\n",
    "print(lemmas_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords (text):#去停用词\n",
    "    filtered_word=[i for i in text if i.lower() not in stopwords_list ]\n",
    "    filtered_text=' '.join(filtered_word)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'footbal famili team sport involv , vari degre , kick ball score goal .'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(lemmas_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['阿萨是', '。', '阿萨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['阿萨是', '。', '阿萨']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "aa=\"阿萨是。阿萨\"\n",
    "a=re.split(r\"(。)\",aa)\n",
    "print(a)\n",
    "re.split(r\"(？|。|！|\\…\\…)\", aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
